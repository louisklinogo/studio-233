# AI Image Generation Fix (Gemini & Mastra)

## Issue Overview
Users reported that generating images via the AI Chat Agent failed with the error: `Error: Gemini did not return an image`.
However, generating images via the Canvas UI (TRPC) appeared to work (or failed silently). The agent claimed to have generated an image, but nothing appeared on the canvas.

## Root Causes Identified

### 1. Incorrect Model Name (Backend Failure)
The codebase was using `gemini-3-pro-preview` for image generation in two places:
- `packages/ai/src/workflows/text-to-image.ts` (Agent Tool)
- `apps/web/src/server/trpc/routers/gemini.ts` (Canvas UI)

**The Problem:** `gemini-3-pro-preview` is primarily a text model in the current API. It does not return image files in the response payload when using the standard `generateText` call, causing the "Gemini did not return an image" error.

**The Solution:**
The correct model ID for image generation via Gemini (Imagen 3 pipeline) is **`gemini-3-pro-image-preview`** (or `gemini-2.5-flash-image-preview`).

### 2. Frontend Stream Handling (UI Failure)
Even after fixing the model name, the image generated by the Agent did not appear on the canvas.

**The Problem:**
The frontend component `ChatPanel.tsx` was listening for standard Vercel AI SDK `tool-invocation` parts or a custom `data-canvas-command` type.
However, the Mastra agent stream returns tool executions in a custom format:
- **Type:** `tool-canvasTextToImageTool` (instead of `tool-invocation`)
- **State:** `output-available` (instead of `result`)
- **Structure:** The output is nested: `output: { command: { url: "...", ... } }`

Because `ChatPanel.tsx` didn't recognize this format, it ignored the successful image generation result.

## Fixes Applied

### 1. Updated Model IDs
We updated both the Agent Workflow and the TRPC Router to use the correct image-capable model.

**File:** `packages/ai/src/workflows/text-to-image.ts`
```typescript
// Old
model: google("gemini-3-pro-preview")

// New
model: google("gemini-3-pro-image-preview")
```

**File:** `apps/web/src/server/trpc/routers/gemini.ts`
```typescript
// Old
model: google("gemini-3-pro-preview")

// New
model: google("gemini-3-pro-image-preview")
```

### 2. Updated Chat Parsing Logic
We patched `ChatPanel.tsx` to correctly parse the Mastra tool result format and dispatch the command to the canvas.

**File:** `apps/web/src/components/studio/chat/ChatPanel.tsx`
```typescript
// Added check for Mastra-specific tool type
if (
    (part as any).type === "tool-canvasTextToImageTool" || 
    ((part as any).type === "tool-invocation" && (part as any).toolInvocation?.toolName === "canvasTextToImageTool")
) {
    // ...
    if (state === "output-available" || state === "result") {
        // Handle nested output structure
        const commandData = output?.command || output;
        if (commandData && commandData.url) {
            // Dispatch to canvas
            onCanvasCommand({
                type: "add-image",
                url: commandData.url,
                // ...
            });
        }
    }
}
```

## Verification
1.  **Backend:** The error `Gemini did not return an image` is gone.
2.  **Frontend:** The chat now logs "I generated an image..." AND the image appears on the canvas.
3.  **Model:** We are correctly using `gemini-3-pro-image-preview`.

## Future Recommendations
*   **Standardize Tool Outputs:** Ensure backend tools return a consistent schema that the frontend expects.
*   **Model Config:** Centralize the Gemini model ID string in `packages/ai/src/model-config.ts` so it only needs to be changed in one place.
