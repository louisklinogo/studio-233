# -*- coding: utf-8 -*-
"""prompt-engineering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vZ8QbRj3pBJzy2mV1-XT5SbPUaoO4D3X
"""



# Commented out IPython magic to ensure Python compatibility.
# %pip install apify-client

import os

from apify_client import ApifyClient
from google.colab import userdata

# Initialize the ApifyClient with API token
APIFY_API_TOKEN = userdata.get('APIFY_API_TOKEN') or os.getenv('APIFY_API_TOKEN')
if APIFY_API_TOKEN is None:
    raise ValueError("APIFY_API_TOKEN must be provided via Colab userdata or environment variables before running this script.")

apify_client = ApifyClient(APIFY_API_TOKEN)

# Replace with the actual ID of the Apify actor
actor_id = "epctex/pinterest-scraper"

# Define your search keywords
keywords = ["male fashion editorial photography", "male high fashion moodboard", "male cinematic fashion photography", "male aesthetic fashion shoot"]

# Prepare the actor input
actor_input = {
    "startUrls": [f"https://www.pinterest.com/search/pins/?q={keyword.replace(' ', '%20')}" for keyword in keywords],
    # Add any other necessary input parameters for the actor based on its documentation
    # For example, you might need to specify the number of results, etc.
    "proxy": {
        "useApifyProxy": True,
        "apifyProxyGroups": ["BUYPROXIES94952"]
    }
}

# Run the actor
run = apify_client.actor(actor_id).call(run_input=actor_input)

# Get the dataset items (results)
for item in apify_client.dataset(run.get('defaultDatasetId')).iterate_items():
    print(item)

"""**Reasoning**:
Define a new string variable `refined_prompt` containing the updated prompt text as described in the instructions.


"""

refined_prompt = """
Act as a professional fashion photographer and expert in analyzing fashion imagery.
Analyze the following image and provide the following information based on the fields in the notes.md file, from the perspective of a fashion professional:

Overall Mood & Story:
- emotional_tone:
- narrative_theme:
- aesthetic_keywords:

Scene & Setting:
- location_type:
- backdrop_description:
- props:
- environment_mood:

Lighting & Color:
- light_quality:
- light_source_direction:
- light_temperature:
- contrast_style:
- color_palette_hex: (Provide 3-7 dominant HEX codes)
- color_theory_relation:
- highlight_shadows_balance:

Camera & Composition:
- camera_angle:
- camera_type_model: (e.g., Canon EOS 5D Mark IV, Nikon D850, Sony Î±7 III)
- focal_length_guess:
- aperture_guess:
- framing: (Describe the framing and subject-to-background relationship)
- composition_rules: (Mention any evident compositional techniques)
- cropping_style:
- movement_capture:

Model Pose & Expression:
- body_pose: (Describe the pose and interaction of each visible model, noting gender presentation)
- head_pose: (Describe the head pose and direction for each model)
- facial_expression: (Describe the expression for each model)
- gesture: (Describe any specific hand or body gestures)
- gaze_direction: (Describe where each model is looking)
- pose_energy: (Characterize the overall energy or stillness of the pose)

Garments & Fashion Details:
- garment_type: (Be specific about the type of garment, e.g., oversized single-breasted blazer, asymmetric draped tunic)
- fit_style:
- length:
- silhouette:
- fabric/material: (Describe texture and sheen if possible)
- pattern:
- color_hex: (Main garment colors)
- details: (Explicitly note unique design features, closures, embellishments, etc.)
- layering_style:

Styling Elements:
- accessories:
- footwear:
- hair_style:
- makeup_style:
- nail_style:
- special_effects:

Editorial & Brand Cues:
- publication_vibe:
- brand_vibe_keywords:
- target_audience_signal:

Technical/Aesthetic Scores:
- aesthetic_score: (Estimate on a scale of 1-10)
- uniqueness_score: (How distinctive the styling/composition feels)

Output Helpers (for Initial Analysis):
- tags: (Short keywords for searching, e.g., "studio, minimalist, monochrome")


Please provide the output in a clear and readable format, like a list for each section. Exclude 'prompt_suggestion' from this initial analysis output as it will be generated in a separate step.
"""

# The subtask is completed, report the finish status and the dataframes.

"""## Load and understand the data

### Subtask:
Load the data from the provided Apify dataset URL.

**Reasoning**:
Load the data from the specified Apify dataset URL using the requests library to retrieve the JSON data.
"""

import requests

APIFY_DATASET_ID = userdata.get('APIFY_DATASET_ID') or os.getenv('APIFY_DATASET_ID')
APIFY_DATASET_TOKEN = (
    userdata.get('APIFY_DATASET_TOKEN')
    or os.getenv('APIFY_DATASET_TOKEN')
    or APIFY_API_TOKEN
)

if not APIFY_DATASET_ID or not APIFY_DATASET_TOKEN:
    raise ValueError(
        "APIFY_DATASET_ID and APIFY_DATASET_TOKEN must be provided before fetching the dataset."
    )

dataset_url = f"https://api.apify.com/v2/datasets/{APIFY_DATASET_ID}/items?token={APIFY_DATASET_TOKEN}"
response = requests.get(dataset_url)

if response.status_code == 200:
    data = response.json()
    if data:
        print("Successfully fetched data.")
        # Optionally, print the first few items to inspect the structure
        # for i, item in enumerate(data):
        #     print(item)
        #     if i >= 5: # Print only the first 6 items as an example
        #         break
    else:
        print("The dataset is empty.")
else:
    print(f"Failed to fetch data. Status code: {response.status_code}")
    print(f"Response: {response.text}")

"""## Load and understand the data

### Subtask:
Examine the structure of the data fetched from the Apify dataset to identify the relevant fields for extraction.

**Reasoning**:
Print the keys of the first item in the data list to understand the top-level structure of each record, convert the data list into a pandas DataFrame named df, display the first 5 rows of the DataFrame df using the display() function to get a visual overview of the data, and print the column names of the DataFrame df to clearly see all available fields.
"""

import pandas as pd

# Assuming 'data' is the list of dictionaries fetched from the Apify dataset
if data:
    # Print keys of the first item to understand the structure
    print("Keys of the first item:")
    print(data[0].keys())

    # Convert the data to a pandas DataFrame for easier inspection and manipulation
    df = pd.DataFrame(data)

    # Display the first few rows and the columns to get an overview
    print("\nFirst 5 rows of the DataFrame:")
    display(df.head())

    print("\nDataFrame columns:")
    print(df.columns)
else:
    print("No data available to inspect.")

"""## Set up the gemini api

### Subtask:
Initialize the Gemini 2.5 Flash model for use.

**Reasoning**:
Initialize the Gemini 2.5 Flash model for use.
"""

import google.generativeai as genai
from google.colab import userdata

# Initialize the Gemini API
try:
    # Check if GOOGLE_API_KEY is already defined (from previous runs), otherwise retrieve it
    if 'GOOGLE_API_KEY' not in globals():
        GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')
        genai.configure(api_key=GOOGLE_API_KEY)
    gemini_model = genai.GenerativeModel('gemini-2.5-flash')
    print("Gemini 2.5 Flash model initialized successfully.")
except Exception as e:
    print(f"Error initializing Gemini model: {e}")
    print("Please ensure you have added your GOOGLE_API_KEY to Colab secrets.")

"""## Load Images

### Subtask:
Load the images from the URLs in the dataset (limited to a manageable number for evaluation).

**Reasoning**:
Iterate through the first 50 items in the data list, fetch each image using its URL, and store the loaded images in a list.
"""

from PIL import Image
import requests
from io import BytesIO

# List to store the loaded images
images = []

# Iterate through the dataset items and limit to the first 50
for i, item in enumerate(data[:50]):
    # Check if the item has image information and a URL
    if 'images' in item and 'orig' in item['images'] and 'url' in item['images']['orig']:
        image_url = item['images']['orig']['url']
        try:
            # Fetch the image from the URL
            response = requests.get(image_url)
            response.raise_for_status() # Raise an exception for bad status codes
            img = Image.open(BytesIO(response.content))
            images.append(img)
            print(f"Successfully loaded image {i+1}/50 from {image_url}")
        except requests.exceptions.RequestException as e:
            print(f"Error fetching image {i+1}/50 from {image_url}: {e}")
        except Exception as e:
            print(f"Error processing image {i+1}/50 from {image_url}: {e}")

print(f"\nLoaded {len(images)} images.")

"""## Perform Initial Image Analysis

### Subtask:
Run the Gemini model with the refined prompt on the loaded images to get detailed analysis for all fields, including `tags`, but *excluding* `prompt_suggestion` in this initial step.

**Reasoning**:
Initialize an empty list to store the analysis results, iterate through the loaded images (up to 50), call the Gemini model with the refined prompt and the image, store the results in a dictionary, append to the list, print the URL and analysis, and include error handling.
"""

# List to store the extracted information for each image
extracted_info_list = []

# Iterate through the loaded images (up to 50) and send them to Gemini for analysis
for i, img in enumerate(images): # images list is already limited to 50
    print(f"Analyzing image {i+1}/{len(images)}...")
    try:
        # Send the image and refined prompt to the Gemini model
        response = gemini_model.generate_content([refined_prompt, img])

        # Store the extracted information
        extracted_info = {
            "image_index": i,
            "image_url": data[i]['images']['orig']['url'] if i < len(data) and 'images' in data[i] and 'orig' in data[i]['images'] and 'url' in data[i]['images']['orig'] else "N/A",
            "analysis": response.text
        }
        extracted_info_list.append(extracted_info)

        # Display the image URL and the extracted analysis in the notebook output
        print(f"\n--- Analysis for Image {i+1} ---")
        print(f"Image URL: {extracted_info['image_url']}")
        print("Extracted Information:")
        print(extracted_info['analysis'])
        print("-" * 30)


    except Exception as e:
        print(f"Error analyzing image {i+1}: {e}")
        # Store an error message if analysis fails
        extracted_info = {
            "image_index": i,
             "image_url": data[i]['images']['orig']['url'] if i < len(data) and 'images' in data[i] and 'orig' in data[i]['images'] and 'url' in data[i]['images']['orig'] else "N/A",
            "analysis": f"Error analyzing image: {e}"
        }
        extracted_info_list.append(extracted_info)
        print(f"\n--- Error Analyzing Image {i+1} ---")
        print(f"Image URL: {extracted_info['image_url']}")
        print(f"Error: {e}")
        print("-" * 30)

print("\nImage analysis complete.")

"""## Generate Prompt Suggestions

### Subtask:
Take the detailed analysis text generated in the initial analysis step and use Gemini with a *new* prompt to synthesize a high-quality, ready-to-use generative `prompt_suggestion` and `tags` based on the full analysis.

**Reasoning**:
Iterate through the detailed analysis results and use the Gemini model with a new prompt to generate the `prompt_suggestion` for each analysis.
"""

# Define the prompt for generating prompt suggestions from analysis text
prompt_suggestion_prompt = """
Based on the following detailed fashion image analysis, generate a single, high-quality, ready-to-use text prompt suitable for a generative image model. The prompt should capture the essence of the analysis, focusing on specific visual details, model poses, expression, camera, overall mood, unique styling elements, composition, lighting, and the overall aesthetic. Ensure the prompt is descriptive enough to guide an image generation model to create an image that is visually similar in style and content to the original analysis.

Provide ONLY the generative prompt text, with no introductory or concluding phrases.

Analysis:
{analysis_text}

Generative Prompt:
"""

# List to store the generated prompt suggestions
generated_prompt_suggestions = []

# Iterate through the extracted_info_list (containing analysis results)
print(f"Generating prompt suggestions for {len(extracted_info_list)} analyzed images...")
for i, analysis_item in enumerate(extracted_info_list):
    analysis_text = analysis_item.get('analysis', '')
    image_index = analysis_item.get('image_index', -1)

    if analysis_text and analysis_text != f"Error analyzing image: {analysis_item.get('error', 'Unknown error')}": # Only process if analysis was successful
        print(f"Generating prompt suggestion for Image {image_index + 1}...")
        try:
            # Format the prompt with the analysis text
            formatted_prompt = prompt_suggestion_prompt.format(analysis_text=analysis_text)

            # Send the formatted prompt to the Gemini model to generate the suggestion
            response = gemini_model.generate_content(formatted_prompt)

            # Extract the generated prompt suggestion (expecting clean plain text output)
            generated_suggestion = response.text.strip()

            generated_prompt_suggestions.append({
                "image_index": image_index,
                "original_image_url": analysis_item.get('image_url', 'N/A'),
                "generated_prompt_suggestion": generated_suggestion
            })
            print(f"Successfully generated prompt suggestion for Image {image_index + 1}.")

        except Exception as e:
            print(f"Error generating prompt suggestion for Image {image_index + 1}: {e}")
            generated_prompt_suggestions.append({
                "image_index": image_index,
                "original_image_url": analysis_item.get('image_url', 'N/A'),
                "generated_prompt_suggestion": f"Error generating suggestion: {e}"
            })
    else:
        print(f"Skipping prompt suggestion generation for Image {image_index + 1} due to no analysis.")
        generated_prompt_suggestions.append({
             "image_index": image_index,
            "original_image_url": analysis_item.get('image_url', 'N/A'),
            "generated_prompt_suggestion": "No analysis available to generate prompt suggestion."
        })


print(f"\nGenerated prompt suggestions for {len(generated_prompt_suggestions)} images.")

# Print the generated prompt suggestions
print("\nGenerated Prompt Suggestions:")
for item in generated_prompt_suggestions:
    print(f"Image {item['image_index'] + 1}: {item['generated_prompt_suggestion']}")
    print("-" * 20)

"""## Generate Images from Refined Prompts

### Subtask:
Use the refined and extracted `prompt_suggestion`s and the `models/gemini-2.5-flash-image-preview` model to generate new images.

**Reasoning**:
Initialize the Gemini 2.5 Flash image generation model and generate images from the cleaned prompt suggestions.
"""

import google.generativeai as genai
from google.colab import userdata

# Initialize the Gemini API (assuming it's not already initialized)
try:
    # Check if GOOGLE_API_KEY is already defined, otherwise retrieve it from userdata
    if 'GOOGLE_API_KEY' not in globals():
        GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')
        genai.configure(api_key=GOOGLE_API_KEY)
    # Initialize the image generation model
    image_model = genai.GenerativeModel('models/gemini-2.5-flash-image-preview')
    print("Gemini 2.5 Flash image generation model initialized successfully.")
except Exception as e:
    print(f"Error initializing Gemini image generation model: {e}")
    print("Please ensure you have added your GOOGLE_API_KEY to Colab secrets.")

# List to store the generated images
generated_images = []

# Iterate through the cleaned prompt suggestions and generate images, limiting to the first 15
for i, item in enumerate(generated_prompt_suggestions[:15]): # Limit to the first 15
    prompt = item.get('generated_prompt_suggestion', '')
    original_image_index = item.get('image_index', -1) # Use original_image_index for clarity

    if prompt and prompt != "No analysis available to generate prompt suggestion." and "Error generating suggestion" not in prompt:
        print(f"Generating image {i+1}/15 for original image index {original_image_index + 1}...")
        try:
            # Generate image from the prompt
            response = image_model.generate_content(prompt)

            # Check if the response contains images and append to the list
            if response and response.candidates and response.candidates[0].content.parts:
                 # Assuming the generated content parts contain image data
                 for part in response.candidates[0].content.parts:
                    # Access attributes using dot notation instead of square brackets
                    if hasattr(part, 'inline_data') and hasattr(part.inline_data, 'mime_type') and part.inline_data.mime_type.startswith('image/'):
                        # Directly append the image part along with original image index and prompt
                        generated_images.append({
                            "original_image_index": original_image_index,
                            "generated_prompt": prompt,
                            "generated_image_part": part
                        })
                        print(f"Successfully generated image {i+1}/15 for original image index {original_image_index + 1}.")
                        break # Assuming one image per prompt
                 else:
                     print(f"No image part found in response for prompt {i+1} (original image index {original_image_index + 1}).")
                     generated_images.append({
                         "original_image_index": original_image_index,
                         "generated_prompt": prompt,
                         "error": "No image generated"
                         }) # Append a placeholder for failed generation

            else:
                print(f"No content or candidates in response for prompt {i+1} (original image index {original_image_index + 1}).")
                generated_images.append({
                    "original_image_index": original_image_index,
                    "generated_prompt": prompt,
                    "error": "Empty response"
                    }) # Append a placeholder for failed generation


        except Exception as e:
            print(f"Error generating image {i+1}/15 for original image index {original_image_index + 1}: {e}")
            generated_images.append({
                "original_image_index": original_image_index,
                "generated_prompt": prompt,
                "error": str(e)
                }) # Append error message for failed generation
    else:
         print(f"Skipping image generation for prompt {i+1}/15 (original image index {original_image_index + 1}) due to missing or error prompt suggestion.")
         generated_images.append({
                "original_image_index": original_image_index,
                "generated_prompt": prompt,
                "error": "Missing or error prompt suggestion"
                })


print(f"\nAttempted to generate {min(15, len(generated_prompt_suggestions))} images. Successfully generated {len([img for img in generated_images if 'generated_image_part' in img])} images.")

from google.colab import drive
drive.mount('/content/drive')

"""## Display Generated Images

### Subtask:
Display the generated images along with their original image URL and the prompt used to generate them.

**Reasoning**:
Iterate through the list of generated images, display each image, and print the corresponding original image URL and the prompt used for generation.
"""

from IPython.display import display, HTML
from PIL import Image

print(f"Displaying {len(generated_images)} generated images:")

for i, item in enumerate(generated_images):
    original_image_index = item.get('original_image_index', -1)
    original_image_url = item.get('original_image_url', 'N/A')
    generated_prompt = item.get('generated_prompt', 'N/A')
    generated_image_part = item.get('generated_image_part')
    error = item.get('error')

    print(f"\n--- Generated Image {i+1} (Original Image Index: {original_image_index + 1}) ---")
    print(f"Original Image URL: {original_image_url}")
    print(f"Prompt Used: {generated_prompt}")

    if generated_image_part:
        try:
            # Access the image data from the part
            image_data = generated_image_part.inline_data.data
            mime_type = generated_image_part.inline_data.mime_type

            # Decode the base64 image data if necessary and display
            if isinstance(image_data, str): # Assuming base64 encoded string
                 from base64 import b64decode
                 image_bytes = b64decode(image_data)
                 img = Image.open(BytesIO(image_bytes))
                 display(img)
            else: # Assuming bytes or similar format directly
                 img = Image.open(BytesIO(image_data))
                 display(img)

        except Exception as e:
            print(f"Error displaying generated image {i+1}: {e}")
            display(HTML(f"<p style='color: red;'>Error displaying image: {e}</p>"))

    elif error:
        print(f"Image generation failed with error: {error}")
        display(HTML(f"<p style='color: red;'>Image generation failed: {error}</p>"))
    else:
        print("No generated image or error information available.")
        display(HTML(f"<p style='color: orange;'>No generated image available.</p>"))

    print("-" * 30)

print("\nFinished displaying generated images.")

"""# Task
Save the generated images from the Colab notebook "https://colab.research.google.com/drive/1vZ8QbRj3pBJzy2mV1-XT5SbPUaoO4D3X#scrollTo=0349c87c" to my Google Drive.

## Mount google drive

### Subtask:
Mount your Google Drive to make it accessible from this Colab notebook.

**Reasoning**:
The previous attempt to mount Google Drive failed. I will try mounting it again to make it accessible for saving files.
"""

from google.colab import drive
drive.mount('/content/drive')